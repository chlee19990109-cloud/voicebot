import streamlit as st
import os
import tempfile
import base64
import re
import json
import time

# [AI & LangChain Libraries]
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
# from langchain.docstore.document import Document
# from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from pptx import Presentation
from openai import OpenAI
import graphviz # ì‹œê°í™” í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬

# [Multimedia Libraries]
try:
    from moviepy import VideoFileClip
except ImportError:
    try:
        from moviepy.editor import VideoFileClip
    except ImportError:
        VideoFileClip = None

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="CampusMind", layout="wide", page_icon="ğŸ§ ")

# [CSS] ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;500;700&display=swap');
    
    h1, h2, h3, h4, h5, h6, p, li, label, textarea, input, div { 
        font-family: 'Noto Sans KR', sans-serif !important; 
    }
    .material-icons, .material-symbols-rounded {
        font-family: 'Material Icons' !important;
    }
    .stButton > button {
        font-family: 'Noto Sans KR', sans-serif !important;
        width: 100%;
    }
    .stMarkdown {
        font-family: 'Noto Sans KR', sans-serif !important;
    }
    .stTabs button {
        font-family: 'Noto Sans KR', sans-serif !important;
    }
    .stExpander {
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        background-color: #ffffff;
        margin-bottom: 10px;
    }
    .stTabs [data-baseweb="tab-list"] button[aria-selected="true"] {
        background-color: #e3f2fd;
        border-top: 3px solid #1976d2;
        color: #0d47a1;
        font-weight: bold;
    }
    /* ì‹œê°í™” ì°¨íŠ¸ ì¤‘ì•™ ì •ë ¬ ë° í¬ê¸° ìµœì í™” */
    [data-testid="stGraphvizChart"] svg {
        max-width: 100% !important;
        height: auto !important;
        display: block;
        margin: 0 auto;
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# [ì–¸ì–´ íŒ© (UI)]
# ==========================================
UI = {
    "Korean": {
        "title": "ğŸ§  CampusMind: ì§€ëŠ¥í˜• í•™ìŠµ ë³´ì¡° ì‹œìŠ¤í…œ",
        "credit": "By ì´ì¶©í™˜",
        "caption": "Architecture: RAG-based LLM Workflow",
        "sidebar_title": "âš™ï¸ ë°ì´í„° ì†ŒìŠ¤",
        "file_label_lec": "ğŸ“š ê°•ì˜ ìë£Œ (PDF, PPT, Word, ì´ë¯¸ì§€, ìŒì„±, ì˜ìƒ ë“±)",
        "file_label_prob": "ğŸ“ ì—°ìŠµ ë¬¸ì œ (PDF, Word ë“±)",
        "apikey": "OpenAI API í‚¤",
        "btn_start": "ğŸš€ ë¶„ì„ ì‹œì‘",
        "tabs": ["ğŸ“ í•µì‹¬ ì •ë¦¬", "ğŸ¨ ì‹œê°í™”", "ğŸƒ í”Œë˜ì‹œì¹´ë“œ", "ğŸ§© í€´ì¦ˆ", "ğŸ§ ì˜¤ë””ì˜¤ ë¸Œë¦¬í•‘", "ğŸ’¬ AI ë„ìš°ë¯¸"],
        "input_topic": "ì£¼ì œ í•„í„° (ì „ë¶€, ì „ì²´, ë¹ˆì¹¸ ì‹œ ì „ì²´ ë²”ìœ„)",
        "ph_topic": "ì˜ˆ: 'ì‹ ê²½ë§' (ì „ë¶€, ì „ì²´, ë¹ˆì¹¸ ì‹œ ì „ì²´ ë²”ìœ„)",
        "msg_proc": "ğŸ“¥ ë°ì´í„° ì²˜ë¦¬ ì¤‘...",
        "msg_ingest": "ì½ëŠ” ì¤‘: ",
        "msg_done": "âœ… ë¶„ì„ ì™„ë£Œ!",
        "msg_err_file": "íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: ",
        "msg_nodata": "ë°ì´í„° ì—†ìŒ.",
        "btn_gen": "ìƒì„±í•˜ê¸°",
        "viz_types": ["Mindmap", "Spider Diagram"],
        "quiz_check": "ì •ë‹µ í™•ì¸",
        "quiz_correct": "ì •ë‹µì…ë‹ˆë‹¤! â­•",
        "quiz_wrong": "ì˜¤ë‹µì…ë‹ˆë‹¤. âŒ",
        "quiz_exp": "í•´ì„¤ ë³´ê¸°",
        "target_lang": "Korean",
        "lbl_card_front": "ì§ˆë¬¸",
        "lbl_card_back": "ì •ë‹µ",
        "audio_btn": "ğŸ™ï¸ ì˜¤ë””ì˜¤ ë¸Œë¦¬í•‘ ìƒì„±",
        "audio_warn": "ë¨¼ì € ìš”ì•½ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
        "spin_gen": "ìƒì„± ì¤‘...",
        "spin_viz": "êµ¬ì¡°í™” ì¤‘...",
        "spin_audio": "ì˜¤ë””ì˜¤ í•©ì„± ì¤‘...",
        "err_viz": "ë Œë”ë§ ì˜¤ë¥˜. Graphvizê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.",
        "err_viz_debug": "DOT ì½”ë“œ í™•ì¸ (ë””ë²„ê¹…)",
        "chat_ph": "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
        "h_bullet": "1. í•µì‹¬ ë‚´ìš© ìš”ì•½",
        "h_table": "2. ìƒì„¸ ìš”ì•½ í‘œ",
        "h_term": "3. ìš©ì–´ ì •ë¦¬",
        "h_th": ["êµ¬ë¶„", "ìƒì„¸ ì„¤ëª…", "ìš©ì–´", "ì •ì˜", "ë¬¸ë§¥"],
        "err_json": "ë°ì´í„° ìƒì„± ì˜¤ë¥˜. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    },
    "English": {
        "title": "ğŸ§  CampusMind: Intelligent Tutor System",
        "credit": "By Choonghwan Lee",
        "caption": "Architecture: RAG-based LLM Workflow",
        "sidebar_title": "âš™ï¸ Data Sources",
        "file_label_lec": "ğŸ“š Lecture Materials (PDF, PPT, Word, Image, Audio, Video)",
        "file_label_prob": "ğŸ“ Practice Problems (PDF, Word)",
        "apikey": "OpenAI API Key",
        "btn_start": "ğŸš€ Analyze",
        "tabs": ["ğŸ“ Summary", "ğŸ¨ Visuals", "ğŸƒ Flashcards", "ğŸ§© Quiz", "ğŸ§ Audio Brief", "ğŸ’¬ AI Tutor"],
        "input_topic": "Topic Filter (All, Everything, Blank for All Sections)",
        "ph_topic": "e.g., 'Neural Networks' (All, Everything, Blank for All Sections)",
        "msg_proc": "ğŸ“¥ Processing Data...",
        "msg_ingest": "Ingesting: ",
        "msg_done": "âœ… Ready!",
        "msg_err_file": "File Error: ",
        "msg_nodata": "No data.",
        "btn_gen": "Generate",
        "viz_types": ["Mindmap", "Spider Diagram"],
        "quiz_check": "Check Answer",
        "quiz_correct": "Correct! â­•",
        "quiz_wrong": "Incorrect. âŒ",
        "quiz_exp": "Explanation",
        "target_lang": "English",
        "lbl_card_front": "Question",
        "lbl_card_back": "Answer",
        "audio_btn": "ğŸ™ï¸ Generate Audio",
        "audio_warn": "Generate summary first.",
        "spin_gen": "Generating...",
        "spin_viz": "Generating diagram...",
        "spin_audio": "Synthesizing...",
        "err_viz": "Rendering Error. Please check Graphviz installation.",
        "err_viz_debug": "View DOT Code",
        "chat_ph": "Ask a question...",
        "h_bullet": "1. Key Highlights",
        "h_table": "2. Detailed Summary Table",
        "h_term": "3. Terminology",
        "h_th": ["Category", "Detailed Content", "Term", "Definition", "Context"],
        "err_json": "Generation Error. Please try again."
    }
}

# ==========================================
# [Core Logic] 1. Ingestion & Vector DB
# ==========================================
def extract_text(file, ext, path, key):
    if ext == ".pdf":
        return "".join([p.page_content for p in PyPDFLoader(path).load()])
    elif ext in [".docx", ".doc"]:
        return "".join([p.page_content for p in Docx2txtLoader(path).load()])
    elif ext in [".pptx", ".ppt"]:
        prs = Presentation(path)
        return "\n".join([s.text for sl in prs.slides for s in sl.shapes if hasattr(s, "text")])
    elif ext in [".jpg", ".png", ".jpeg"]:
        client = OpenAI(api_key=key)
        with open(path, "rb") as f: enc = base64.b64encode(f.read()).decode('utf-8')
        res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": [{"type": "text", "text": "Extract all text visible in this slide/image precisely."}, {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{enc}"}}]}] )
        return f"[Image Source: {file.name}] " + res.choices[0].message.content
    elif ext in [".mp3", ".wav", ".m4a"]:
        client = OpenAI(api_key=key)
        with open(path, "rb") as f: txt = client.audio.transcriptions.create(model="whisper-1", file=f).text
        return f"[Audio Source: {file.name}] " + txt
    elif ext in [".mp4", ".avi", ".mov"]:
        if VideoFileClip is None: return "Error: MoviePy missing."
        audio_path = path + "_temp.mp3"
        try:
            vid = VideoFileClip(path)
            vid.audio.write_audiofile(audio_path, logger=None)
            client = OpenAI(api_key=key)
            with open(audio_path, "rb") as f: txt = client.audio.transcriptions.create(model="whisper-1", file=f).text
            return f"[Video Source: {file.name}] " + txt
        except Exception as e: return str(e)
        finally:
            if os.path.exists(audio_path): os.remove(audio_path)
    return ""

def build_knowledge_base(lec_files, prob_files, key, ui_text):
    docs = []
    status = st.status(ui_text["msg_proc"], expanded=True)
    
    def process_files(file_list, source_type):
        for f in file_list:
            ext = os.path.splitext(f.name)[1].lower()
            status.write(f"{ui_text['msg_ingest']} [{source_type}] {f.name}")
            with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
                tmp.write(f.getvalue())
                tmp_path = tmp.name
            try:
                content = extract_text(f, ext, tmp_path, key)
                if content: 
                    # [í•µì‹¬] í…ìŠ¤íŠ¸ ë§¨ ì•ì— ì†ŒìŠ¤ íƒ€ì…ì„ ëª…ì‹œí•˜ì—¬ AIê°€ êµ¬ë¶„í•˜ê¸° ì‰½ê²Œ í•¨
                    tagged_content = f"[{source_type}] \n{content}"
                    docs.append(Document(page_content=tagged_content, metadata={"source": f.name, "type": source_type}))
            except Exception as e: st.error(f"{ui_text['msg_err_file']} {e}")
            finally: os.remove(tmp_path)

    if lec_files: process_files(lec_files, "Lecture Material")
    if prob_files: process_files(prob_files, "Practice Problem")
    
    if not docs:
        status.update(label=ui_text["msg_nodata"], state="error")
        return None

    # ì²­í¬ ì‚¬ì´ì¦ˆë¥¼ ì¡°ê¸ˆ ëŠ˜ë ¤ì„œ ë¬¸ë§¥ íŒŒì•… ëŠ¥ë ¥ í–¥ìƒ
    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    splits = splitter.split_documents(docs)
    db = FAISS.from_documents(splits, OpenAIEmbeddings(openai_api_key=key))
    status.update(label=ui_text["msg_done"], state="complete", expanded=False)
    return db

def get_rag_chain(db, key, target_lang):
    llm = ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=key)
    
    # [í•µì‹¬] ì—°ìŠµ ë¬¸ì œ íƒœê·¸ë¥¼ ë³´ê³  ìŠ¤íƒ€ì¼ì„ ë¶„ì„í•˜ë„ë¡ ì§€ì‹œ
    template = f"""
    You are an intelligent AI Teaching Assistant and Exam Strategist.
    
    *** SOURCE IDENTIFICATION ***
    - Text starting with `[Lecture Material]` is conceptually explanatory.
    - Text starting with `[Practice Problem]` contains actual exam/quiz questions.

    *** INSTRUCTIONS ***
    1. **Concept Explainer**: If asked about concepts, prioritize `[Lecture Material]`.
    2. **Exam Strategist**: If asked about "exam style", "preparation", or "types of problems":
       - Look strictly at the content labeled `[Practice Problem]`.
       - Analyze the format (Multiple choice? Essay? Calculation?) and difficulty.
       - Provide a strategy based on those specific patterns.
       - If no `[Practice Problem]` is found, state that you need practice files to analyze the exam style.
    
    *** STRICT RULES ***
    - Answer ONLY using the provided [Context].
    - Output Language: **{target_lang}**.
    
    [Context]:
    {{context}}
    
    [User Question]:
    {{question}}
    """
    
    retriever = db.as_retriever(
        search_type="mmr", 
        search_kwargs={'k': 20, 'fetch_k': 50, 'lambda_mult': 0.6}
    )
    
    return RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type_kwargs={"prompt": PromptTemplate(template=template, input_variables=["context", "question"])}
    )

# ==========================================
# [Core Logic] 2. Generation Functions
# ==========================================
def get_scope(topic):
    return "the ENTIRE provided material" if not topic or not topic.strip() else f"the topic '{topic}'"

def clean_json(text):
    text = text.strip()
    text = re.sub(r"```(json)?", "", text, flags=re.IGNORECASE).replace("```", "")
    match = re.search(r"(\[.*\])", text, re.DOTALL)
    if match: text = match.group(1)
    text = re.sub(r",\s*\]", "]", text)
    return text

def clean_dot_code(text):
    text = text.strip()
    text = re.sub(r"```(dot)?", "", text).replace("```", "")
    start_idx = text.find("digraph")
    if start_idx == -1: return text 
    open_brace = text.find("{", start_idx)
    if open_brace == -1: return text
    close_brace = text.rfind("}")
    if close_brace == -1: return text
    return text[start_idx : close_brace+1]

# ìš©ì–´ ì •ë¦¬ ë° ìš”ì•½
def gen_summary(db, api_key, topic, ui_text):
    # ì…ë ¥ê°’ ë¶„ì„ (ì „ì²´ vs íŠ¹ì • í† í”½)
    is_all_mode = False
    if not topic or topic.strip().lower() in ["all", "ì „ë¶€", "ì „ì²´", "everything"]:
        is_all_mode = True
        scope_text = "the ENTIRE provided material (All lectures)"
    else:
        scope_text = f"the specific topic '{topic}'"

    lang = ui_text["target_lang"]
    
    # ëª¨ë“œì— ë”°ë¥¸ ì„¤ì •
    if is_all_mode:
        # [ì „ì²´ ëª¨ë“œ]
        # ê²€ìƒ‰ì–´: ì „ì²´ êµ¬ì¡°ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆëŠ” í¬ê´„ì  í‚¤ì›Œë“œ
        search_query = "Table of contents, Lecture titles, Course outline, Key concepts summary"
        k_val = 80  # ì „ì²´ë¥¼ ë´ì•¼ í•˜ë¯€ë¡œ ë§ì€ ì²­í¬(80ê°œ)ë¥¼ ê°€ì ¸ì˜´
        
        mode_instruction = f"""
        - **Goal**: Create a **"Master Course Outline"** that lists **EVERY** detected file or lecture.
        - **Constraint**: Keep descriptions concise to ensure ALL lectures are covered within the output limit.
        - **Coverage**: It is critical to list **ALL** lectures/files found in the text. Do not stop after the first few.
        - **Format**: For each lecture, provide a brief summary and a list of key exam concepts.
        """
        
        # [ì „ì²´ ëª¨ë“œ ê°€ì´ë“œë¼ì¸]
        guidelines = f"""
        1. **Context-Based**: Answer ONLY based on the provided [Context].
        2. **Completeness (CRITICAL)**: 
           - You MUST iterate through **ALL** detected files/lectures.
           - Do not skip the later lectures. 
        3. **Terminology Integrity (STRICT)**: 
           - Even in the concept list, terms must be a **VERBATIM COPY** from the source.
           - **DO NOT TRANSLATE THE TERM ITSELF.**
        """

        # [ì „ì²´ ëª¨ë“œ í¬ë§·] (í‘œ ì—†ëŠ” ê²½ëŸ‰í™” êµ¬ì¡°)
        format_instruction = f"""
        **[INSTRUCTION: Repeat the block below for EVERY detected File/Lecture]**

        ## ğŸ“‚ [Insert File or Lecture Name]
        
        ### ğŸ“– {ui_text['h_bullet']} (Lecture Overview)
        - (Summarize the main theme of this lecture in 2-3 sentences in {lang}.)
        
        ### ğŸ”‘ Key Exam Concepts
        - **(Concept 1)**: (Short definition/Core logic in {lang})
        - **(Concept 2)**: (Short definition/Core logic in {lang})
        - **(Concept 3)**: (Short definition/Core logic in {lang})
        
        ---
        """
    
    else:
        # [íŠ¹ì • í† í”½ ëª¨ë“œ]
        search_query = topic
        k_val = 15  # íŠ¹ì • í† í”½ ì§‘ì¤‘
        
        mode_instruction = f"""
        - **Scope Focus**: Focus **DEEPLY and STRICTLY** on the concept of '{topic}'. Ignore unrelated sections.
        - **Terminology Strategy**: Select terms that are **semantically related** to '{topic}' (e.g., sub-concepts, components, algorithms).
        """
        
        # [íŠ¹ì • í† í”½ ê°€ì´ë“œë¼ì¸] (ì œê³µí•´ì£¼ì‹  ë‚´ìš© ê·¸ëŒ€ë¡œ ì ìš©)
        guidelines = f"""
        1. **Context-Based**: Answer ONLY based on the provided [Context].
        2. **Comprehensive Coverage**: 
           - Do NOT limit the number of key points.
           - Extract **ALL** core concepts, definitions, formulas, and arguments.
           - Aim for high detail.
        3. **Terminology Integrity (STRICT)**: 
           - In the Terminology Table, the 'Term' column must be a **VERBATIM COPY** from the source text.
           - **DO NOT TRANSLATE THE TERM ITSELF.**
           - If the source uses English (e.g., "Backpropagation"), keep it "Backpropagation".
           - If the source uses Korean (e.g., "ì—­ì „íŒŒ"), keep it "ì—­ì „íŒŒ".
           - Only the Definition and Context columns should be in **{lang}**.
        """
        
        # [íŠ¹ì • í† í”½ í¬ë§·]
        format_instruction = f"""
        ### {ui_text['h_bullet']}
        - (List **ALL** exam-relevant key points about '{topic}' in {lang}.)
        
        ### {ui_text['h_table']}
        | {ui_text['h_th'][0]} | {ui_text['h_th'][1]} |
        |---|---|
        | (Category in {lang}) | (Detailed explanation in {lang}) |
        
        ### {ui_text['h_term']}
        | {ui_text['h_th'][2]} | {ui_text['h_th'][3]} | {ui_text['h_th'][4]} |
        |---|---|---|
        | **(EXACT SOURCE TERM)** | (Definition in {lang}) | (Context/Relation in {lang}) |
        """

    # [í•µì‹¬] DB ê²€ìƒ‰ ìˆ˜í–‰
    # DBê°€ ë¹„ì–´ìˆëŠ”ì§€ ì²´í¬
    if db is None:
        return "Error: Database is not initialized."
    
    # DBì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    docs = db.similarity_search(search_query, k=k_val)
    context = "\n".join([d.page_content for d in docs])

    # í”„ë¡¬í”„íŠ¸ ì¡°í•©
    prompt = f"""
    You are an expert **Professor** and **Exam Preparation Tutor**.
    Analyze {scope_text} based STRICTLY on the provided context.
    
    *** MODE INSTRUCTION ***
    {mode_instruction}
    
    *** CRITICAL GUIDELINES ***
    {guidelines}

    *** OUTPUT FORMAT ***
    {format_instruction}

    [Context]:
    {context}
    """
    
    # [í•µì‹¬] LLM ì§ì ‘ í˜¸ì¶œ
    try:
        llm = ChatOpenAI(model="gpt-4o", temperature=0.3, openai_api_key=api_key)
        response = llm.invoke(prompt)
        return response.content
    except Exception as e:
        return f"Error during generation: {str(e)}"

# ì‹œê°í™” (ë§ˆì¸ë“œë§µ, ìŠ¤íŒŒì´ë” ë‹¤ì´ì–´ê·¸ë¨)
def gen_diagram_optimized(db, api_key, topic, viz_type, ui_text):
    # 1. ì…ë ¥ê°’ ë¶„ì„ (ì „ì²´ vs íŠ¹ì • í† í”½)
    is_all_mode = False
    if not topic or topic.strip().lower() in ["all", "ì „ë¶€", "ì „ì²´", "everything"]:
        is_all_mode = True
        
    # 2. ê²€ìƒ‰ ì „ëµ ë° í”„ë¡¬í”„íŠ¸ ì§€ì¹¨ ì„¤ì •
    if is_all_mode:
        # [ì „ì²´ ëª¨ë“œ]
        search_query = "Table of Contents, Course Syllabus, All Lecture Titles, All Chapter Titles, Lecture 1, Lecture 2, ..., Lecture N"
        search_type = "mmr" 
        k_val = 300     # ì „ì²´ ë²”ìœ„ë¥¼ ì»¤ë²„í•˜ê¸° ìœ„í•´ ìœ ì§€
        fetch_k = 3000
        
        root_node = "Course Overview"
        
        # â˜… ì „ì²´ ëª¨ë“œ ì§€ì¹¨
        scope_instruction = """
        - **MODE**: Full Course Syllabus & Key Concepts.
        - **GOAL**: Visualize **EVERY SINGLE** Lecture/Chapter found in the files, and optionally attach 2-3 key concepts to each lecture.
        - **CRITICAL REQUIREMENT (NO OMISSION)**: 
            1. **Exhaustive List**: Look at the [Source File] names and context. You MUST create a node for EVERY lecture present (e.g., Lecture 1 to Lecture N). **DO NOT SKIP ANY LECTURE.**
            2. **Hierarchy**: Root -> Lecture Node (Level 1) -> Keyword Nodes (Level 2).
            3. **NO EDGE LABELS**: Edges must be plain lines. **Put all text INSIDE the Node.**
            4. **Logical Order**: Arrange nodes in the order.
        - **NAMING RULES (CRITICAL)**:
            1. Node Label: "Lec X: [Title]" (e.g., "Lec 2: Metals", "Lec 5: Composites").
               - BAD: "Lecture 2" -> "Metals" (Do not split).
               - GOOD: Root -> "Lec 2: Metals".
            2. Keyword Label: Use the exact term from the context (e.g., "Thermodynamics", "Stress-Strain Curve").
            3. **NO EDGE LABELS**: Edges must be plain lines. Text goes inside nodes.
        """
        
    else:
        # [íŠ¹ì • í† í”½ ëª¨ë“œ]
        search_query = f"Structure and details of '{topic}', sub-types, components, key features"
        search_type = "similarity" 
        k_val = 15
        fetch_k = 0
        
        root_node = topic.strip()
        
        scope_instruction = f"""
        - **MODE**: Structured Deep Dive.
        - **GOAL**: Visualize the **Structure** of '{topic}' concisely.
        - **STYLE**:
            1. Root ('{topic}') -> Sub-Components / Types (Level 1).
            2. Sub-Components -> Key Characteristics (Level 2).
            3. **Constraint**: Use short phrases in nodes (Max 5-8 words). Avoid long sentences.
            4. **NO EDGE LABELS**: Edges must be plain lines. Text goes inside nodes.
        """

    # 3. ë¬¸ì„œ ê²€ìƒ‰
    try:
        if search_type == "mmr":
            # fetch_kë¥¼ ì¶©ë¶„íˆ ì£¼ì–´ ë‹¤ì–‘ì„± í™•ë³´
            docs = db.max_marginal_relevance_search(search_query, k=k_val, fetch_k=fetch_k)
        else:
            docs = db.similarity_search(search_query, k=k_val)
    except Exception as e:
        print(f"Search Error: {e}")
        docs = db.similarity_search(search_query, k=k_val)
    
    # â˜… í•µì‹¬ íŒŒíŠ¸: Contextì— 'íŒŒì¼ëª…(Source)'ì„ ì§ì ‘ ëª…ì‹œí•˜ì—¬ AIê°€ ëˆ„ë½ ì—†ì´ ì „ì²´ ê°•ì˜ë¥¼ íŒŒì•…í•˜ê²Œ í•¨
    context_chunks = []
    for d in docs:
        # metadataì—ì„œ íŒŒì¼ëª…ì„ ì¶”ì¶œ (ê²½ë¡œ ì œì™¸)
        source = d.metadata.get('source', '')
        if source:
            filename = source.split('/')[-1].split('\\')[-1]
            context_chunks.append(f"--- [Source File: {filename}] ---\n{d.page_content}")
        else:
            context_chunks.append(d.page_content)
            
    context = "\n\n".join(context_chunks)
    
    if not context:
        return 'digraph G { "No Data" [shape=box]; }'
    
    # Context ê¸¸ì´ ì œí•œ (í† ê·¼ ì´ˆê³¼ ë°©ì§€)
    # í•œê¸€/ì˜ì–´ í˜¼ìš© ì‹œ 1í† í° â‰ˆ 2~3 char.
    # 50,000ì â‰ˆ 15,000 ~ 20,000 í† í° (ì•ˆì „ êµ¬ê°„)
    safe_context = context[:50000]

    llm = ChatOpenAI(model="gpt-4o", temperature=0, openai_api_key=api_key)
    font_attr = 'fontname="Malgun Gothic, AppleGothic, sans-serif"'
    
    # 4. ì‹œê°í™” ìŠ¤íƒ€ì¼ ì„¤ì •
    no_edge_text = 'label="", xlabel="",' 
    
    if "Mind" in viz_type:
        layout_engine = "dot"
        rank_dir = "LR" 
        
        # ì „ì²´ ëª¨ë“œì¼ ê²½ìš° ë…¸ë“œ ê°„ê²©(ranksep)ì„ ì¡°ê¸ˆ ë” ì¢í˜€ì„œ í•œëˆˆì— ë“¤ì–´ì˜¤ê²Œ ì¡°ì •
        sep_settings = 'nodesep=0.25; ranksep=0.8;' if is_all_mode else 'nodesep=0.3; ranksep=1.0;'
        graph_attr = f'rankdir={rank_dir}; splines=ortho; {sep_settings} compound=true;'
        
        # ë…¸ë“œ ìŠ¤íƒ€ì¼
        if is_all_mode:
            # ì „ì²´ ëª¨ë“œ: ë°•ìŠ¤í˜•, ì—°í•œ íŒŒë‘
            node_def = f'node [shape=box, style="filled,rounded", fillcolor="#E3F2FD", penwidth=1.0, fontsize=12, {font_attr}];'
        else:
            # ìƒì„¸ ëª¨ë“œ: ë…¸íŠ¸í˜•, ì—°í•œ ë…¸ë‘
            node_def = f'node [shape=note, style="filled,rounded", fillcolor="#FFF9C4", penwidth=1.0, fontsize=12, margin="0.1,0.1", {font_attr}];'
            
        edge_def = f'edge [arrowhead=vee, arrowsize=0.5, color="#546E7A", {no_edge_text} {font_attr}];'
        
        viz_rules = f"""
        2. **Mindmap Rules**:
            - **Root Node**: Label: **"{root_node}"** (Shape: doubleoctagon, Color: #FFCCBC).
            - **NO EDGE TEXT**: Strictly forbidden. Use plain lines only.
            - **Consistency**: Ensure lecture names correspond to the context provided.
        """
    else:
        # Spider Diagram
        layout_engine = "neato"
        graph_attr = 'overlap=false; splines=curved; sep="+25,25"; esep="+10,10"; start=regular;'
        node_def = 'node [shape=plaintext, fontcolor="#37474F", fontsize=11, ' + font_attr + '];'
        edge_def = f'edge [arrowhead=none, color="#B0BEC5", len=2.5, penwidth=1.0, {no_edge_text} {font_attr}];'
        
        viz_rules = f"""
        2. **Spider Diagram Rules**:
            - **Root Node**: Center node **"{root_node}"**.
            - **NO EDGE TEXT**: Strictly forbidden.
        """

    # 5. í”„ë¡¬í”„íŠ¸ ì¡°í•©
    prompt = f"""
    Role: Expert Curriculum Designer & Data Visualization Specialist.
    Task: Generate Graphviz DOT code based on the [Context].
    
    *** VISUALIZATION INSTRUCTION ***
    {scope_instruction}
    
    [Context]
    {safe_context} 
    
    *** STRICT RULES ***
    1. Use ONLY information from the Context.
    2. **Language**: Use the same language as the Context.
    3. **CLEAN EDGES**: **NEVER** put text on edges. Just A -> B.
    4. **NO GENERIC NAMES**: Use the real lecture titles from the [Source File] names or text.
       - FORBIDDEN: "keyword1", "nodeA", "Lecture X".
       - REQUIRED: "Structure", "Thermodynamics", "Lec 2: Metals".
    {viz_rules}
    
    Template:
    digraph G {{
        layout={layout_engine};
        {graph_attr}
        {node_def}
        {edge_def}
        
        // Root Node
        root [label="{root_node}", shape=doubleoctagon, style=filled, fillcolor="#FFCCBC", fontsize=14];
                
        // Define Nodes & Edges
        // ... (Generate nodes for ALL chapters found in context)
    }}
    """
    
    try:
        # invoke ì‚¬ìš© (LangChain ìµœì‹  ë²„ì „ í˜¸í™˜)
        res = llm.invoke(prompt).content
        return clean_dot_code(res)
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì‚¬ìš©ìì—ê²Œ íŒíŠ¸ë¥¼ ì£¼ëŠ” ë…¸ë“œ ìƒì„±
        return f'digraph G {{ "Error" [label="Error: {str(e)[:40]}...", shape=box, style=filled, fillcolor="#FFCDD2"]; }}'

# í”Œë˜ì‹œì¹´ë“œ
def gen_flashcards(db, api_key, topic, ui_text):
    lang = ui_text["target_lang"]
    
    # 1. ì…ë ¥ê°’ ë¶„ì„ (ì „ì²´ vs íŠ¹ì • í† í”½)
    is_all_mode = False
    if not topic or topic.strip().lower() in ["all", "ì „ë¶€", "ì „ì²´", "everything"]:
        is_all_mode = True

    # 2. ê²€ìƒ‰ ë° í”„ë¡¬í”„íŠ¸ ì „ëµ ì„¤ì •
    if is_all_mode:
        # [ì „ì²´ ëª¨ë“œ]
        search_query = "Important definitions, core concepts, exam questions, summary"
        # kë¥¼ ëŒ€í­ ëŠ˜ë¦¼ (ë” ë§ì€ ë‚´ìš©ì„ ì°¸ì¡°í•˜ì—¬ ë§ì´ ìƒì„±í•˜ê¸° ìœ„í•¨)
        k_val = 80 
        scope_instruction = """
        - **Quantity**: **DO NOT LIMIT** the number of cards. Generate as many flashcards as possible to cover the entire context exhaustively.
        - **Scope**: Cover the **ENTIRE breadth** of the provided material from start to finish.
        - **Diversity**: Extract key questions from ALL sections (intro, body, conclusion).
        """
    else:
        # [íŠ¹ì • í† í”½ ëª¨ë“œ]
        search_query = topic
        k_val = 15 # íŠ¹ì • í† í”½
        scope_instruction = f"""
        - **Quantity**: Create a comprehensive set of flashcards (no fixed limit) to fully master '{topic}'.
        - **Scope**: Focus **STRICTLY** on the concept of '{topic}'.
        - **Depth**: Ask about definitions, sub-concepts, differences, and applications related specifically to '{topic}'.
        """

    # 3. ë¬¸ì„œ ê²€ìƒ‰ (ëŠ˜ì–´ë‚œ k_val ì‚¬ìš©)
    docs = db.similarity_search(search_query, k=k_val)
    context = "\n".join([d.page_content for d in docs])
    
    # 4. í”„ë¡¬í”„íŠ¸ ìƒì„±
    client = OpenAI(api_key=api_key)
    prompt = f"""
    Role: Exam Prep Tutor.
    Task: Create a comprehensive list of Q&A flashcards based on the [Context].
    
    *** SCOPE INSTRUCTION ***
    {scope_instruction}

    Language: {lang}.
    Format: JSON Array ONLY. Keys: "front" (Question), "back" (Short Answer).
    
    [Context]:
    {context[:15000]} # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œì„ 15000ìœ¼ë¡œ ëŒ€í­ ëŠ˜ë¦¼ (ì¬ë£Œê°€ ë§ì•„ì•¼ ë§ì´ ë§Œë“¦)
    
    Output example: [{{"front": "What is X?", "back": "X is Y."}}, {{"front": "...", "back": "..."}}]
    """
    
    try:
        # max_tokensë¥¼ ëŠ˜ë¦¬ê±°ë‚˜ ê¸°ë³¸ê°’(ëª¨ë¸ ìµœëŒ€ì¹˜)ì„ ì‚¬ìš©í•˜ë„ë¡ ë‘ì–´ ì¶œë ¥ì´ ì˜ë¦¬ì§€ ì•Šê²Œ í•¨
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "system", "content": "You are a JSON generator."}, 
                      {"role": "user", "content": prompt}],
            temperature=0.5
        )
        res = response.choices[0].message.content
        return json.loads(clean_json(res))
    except Exception as e:
        return [{"front": "Error", "back": f"Failed to generate: {str(e)}"}]

# í€´ì¦ˆ
def gen_quiz(db, api_key, topic, ui_text):
    lang = ui_text["target_lang"]
    
    # 1. ì…ë ¥ê°’ ë¶„ì„ (ì „ì²´ vs íŠ¹ì • í† í”½)
    is_all_mode = False
    if not topic or topic.strip().lower() in ["all", "ì „ë¶€", "ì „ì²´", "everything", "total"]:
        is_all_mode = True

    # 2. ê²€ìƒ‰ ë° í”„ë¡¬í”„íŠ¸ ì „ëµ ì„¤ì •
    if is_all_mode:
        # [ì „ì²´ ëª¨ë“œ]
        search_query = "Exam questions, practice problems, core concepts, critical knowledge"
        # ë¬¸ì œë¥¼ ë§ì´ ë‚´ë ¤ë©´ ì¬ë£Œê°€ ë§ì•„ì•¼ í•˜ë¯€ë¡œ kë¥¼ 80ìœ¼ë¡œ ëŒ€í­ ì¦ê°€
        k_val = 80
        scope_instruction = """
        - **Quantity**: **DO NOT LIMIT** the number of questions. Generate as many unique questions as possible (e.g., 10, 20, or more) to cover the entire context exhaustively.
        - **Scope**: Questions must cover **various lectures/sections** of the provided material, not just one.
        - **Diversity**: Ensure questions range from fundamental definitions to complex applications found across the entire text.
        """
    else:
        # [íŠ¹ì • í† í”½ ëª¨ë“œ]
        search_query = topic
        k_val = 15 # íŠ¹ì • í† í”½ë„ ê¹Šê²Œ íŒŒê¸° ìœ„í•´ ì¡°ê¸ˆ ëŠ˜ë¦¼
        scope_instruction = f"""
        - **Quantity**: Create a comprehensive set of questions (no fixed limit) to fully master '{topic}'.
        - **Scope**: Focus **STRICTLY** on the concept of '{topic}'.
        - **Depth**: Create questions that test the definition, usage, nuances, and common misconceptions of '{topic}' specifically.
        """

    # 3. ë¬¸ì„œ ê²€ìƒ‰ (ëŠ˜ì–´ë‚œ k_val ì‚¬ìš©)
    docs = db.similarity_search(search_query, k=k_val)
    context = "\n".join([d.page_content for d in docs])
    
    # 4. í”„ë¡¬í”„íŠ¸ ìƒì„±
    client = OpenAI(api_key=api_key)
    prompt = f"""
    Role: Professor.
    Task: Create a comprehensive set of multiple-choice questions based on [Context].
    
    *** SCOPE INSTRUCTION ***
    {scope_instruction}

    Language: {lang}.
    Format: JSON Array ONLY.
    
    Requirements:
    - 4 Options per question.
    - Include clear "explanation" for the correct answer.
    - **Randomize the position of the correct answer** (do not always make 'A' the answer).
    - **IMPORTANT**: The 'answer' field must be the **EXACT String value** from the 'options' list, NOT just 'A', 'B', 'C', or 'D'.
    
    [Context]:
    {context[:15000]} # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ 15000ìœ¼ë¡œ ëŒ€í­ ëŠ˜ë¦¼ (ë¬¸ì œë¥¼ ë§ì´ ë§Œë“¤ê¸° ìœ„í•¨)
    
    Output example: 
    [{{"question":"What is 1+1?", "options":["3","2","5","4"], "answer":"2", "explanation":"1+1 equals 2."}}]
    """
    
    try: 
        # max_tokens ì œí•œì— ê±¸ë¦¬ì§€ ì•Šë„ë¡ ì£¼ì˜ (GPT-4oëŠ” ì¶œë ¥ í† í° ì—¬ìœ ê°€ í¼)
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "system", "content": "You are a JSON generator."}, 
                      {"role": "user", "content": prompt}],
            temperature=0.5
        )
        res = response.choices[0].message.content
        return json.loads(clean_json(res))
    except Exception as e:
        return [{"question": "Error", "options": ["Error"], "answer": "Error", "explanation": str(e)}]

# ==========================================
# [UI] Main Application
# ==========================================
keys = ["chain", "summary", "diagram", "quiz_data", "flashcards", "messages", "db", "api_key"]
for k in keys:
    if k not in st.session_state: st.session_state[k] = None
if st.session_state.messages is None: st.session_state.messages = []

with st.sidebar:
    lang_opt = st.radio("ì–¸ì–´ ëª¨ë“œ / Language Mode", ["Korean", "English"], horizontal=True)
    ui = UI[lang_opt]
    
    st.title(ui["sidebar_title"])
    api_key_input = st.text_input(ui["apikey"], type="password")
    
    lec_files = st.file_uploader(ui["file_label_lec"], accept_multiple_files=True, key="lec")
    prob_files = st.file_uploader(ui["file_label_prob"], accept_multiple_files=True, key="prob")
    
    if st.button(ui["btn_start"], type="primary"):
        if api_key_input and (lec_files or prob_files):
            st.session_state.api_key = api_key_input
            # ë¶„ë¦¬ëœ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ DB ìƒì„± í•¨ìˆ˜ì— ì „ë‹¬
            db = build_knowledge_base(lec_files, prob_files, api_key_input, ui)
            if db:
                st.session_state.db = db
                st.session_state.chain = get_rag_chain(db, api_key_input, ui["target_lang"])
                st.session_state.summary = None
                st.session_state.diagram = None
                st.rerun()

st.title(ui["title"])
st.markdown(f"**{ui['credit']}**")
st.caption(ui["caption"])

if st.session_state.chain and st.session_state.db:
    t1, t2, t3, t4, t5, t6 = st.tabs(ui["tabs"])

    with t1: # ìš”ì•½
        topic_s = st.text_input("Topic_Sum", placeholder=ui["ph_topic"], label_visibility="collapsed")
        if st.button(ui["btn_gen"], key="sum"):
            with st.spinner(ui["spin_gen"]):
                st.session_state.summary = gen_summary(
                    st.session_state.db,       # DB ê°ì²´ ì „ë‹¬
                    st.session_state.api_key,  # api_key ì „ë‹¬
                    topic_s, 
                    ui
                    )
        if st.session_state.summary: st.markdown(st.session_state.summary)

    with t2: # ì‹œê°í™”
        c1, c2, c3 = st.columns([2, 3, 1])
        with c1:
            v_type = st.selectbox("Style", ui["viz_types"], label_visibility="collapsed")
        with c2:
            topic_v = st.text_input("Viz_Topic", placeholder=ui["ph_topic"], label_visibility="collapsed")
        with c3:
            if st.button(ui["btn_gen"], key="viz", use_container_width=True):
                with st.spinner(ui["spin_viz"]):
                    st.session_state.diagram = gen_diagram_optimized(
                        st.session_state.db, 
                        st.session_state.api_key, 
                        topic_v, 
                        v_type, 
                        ui
                    )
        
        if st.session_state.diagram:
            try:
                st.graphviz_chart(st.session_state.diagram, use_container_width=True)
                with st.expander(ui["err_viz_debug"]):
                    st.code(st.session_state.diagram, language="dot")
            except Exception as e:
                st.error(f"{ui['err_viz']} ({str(e)})")
                st.code(st.session_state.diagram)

    with t3: # í”Œë˜ì‹œì¹´ë“œ
        topic_f = st.text_input("Topic_Flash", placeholder=ui["ph_topic"], label_visibility="collapsed")
        if st.button(ui["btn_gen"], key="flash"):
            with st.spinner(ui["spin_gen"]):
                # ë°ì´í„° ìƒì„± ë° ì €ì¥
                st.session_state.flashcards = gen_flashcards(st.session_state.db, st.session_state.api_key, topic_f, ui)
        
        # í™”ë©´ ì¶œë ¥ ë¡œì§
        if st.session_state.flashcards:
            # ì—ëŸ¬ ë©”ì‹œì§€ê°€ ë‹´ê²¨ ìˆëŠ”ì§€, ì •ìƒ ë°ì´í„°ì¸ì§€ í™•ì¸
            if isinstance(st.session_state.flashcards, list) and len(st.session_state.flashcards) > 0 and "front" in st.session_state.flashcards[0]:
                cols = st.columns(2)
                for i, c in enumerate(st.session_state.flashcards):
                    with cols[i % 2]:
                        st.info(f"**Q{i+1}: {c['front']}**")
                        with st.expander(ui['lbl_card_back']):
                            st.write(c['back'])
            else:
                # ìƒì„± ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
                st.error(ui["err_json"])
                st.write(st.session_state.flashcards)

    with t4: # í€´ì¦ˆ
        topic_q = st.text_input("Topic_Quiz", placeholder=ui["ph_topic"], label_visibility="collapsed")
        if st.button(ui["btn_gen"], key="quiz"):
            with st.spinner(ui["spin_gen"]):
                # ë°ì´í„° ìƒì„± ë° ì €ì¥
                st.session_state.quiz_data = gen_quiz(st.session_state.db, st.session_state.api_key, topic_q, ui)
                # í€´ì¦ˆëŠ” ë¼ë””ì˜¤ ë²„íŠ¼ ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•´ rerunì´ ìœ ìš©í•  ìˆ˜ ìˆìŒ
                st.rerun()

        # í™”ë©´ ì¶œë ¥ ë¡œì§
        if st.session_state.quiz_data:
            if isinstance(st.session_state.quiz_data, list) and len(st.session_state.quiz_data) > 0 and "question" in st.session_state.quiz_data[0]:
                for i, q in enumerate(st.session_state.quiz_data):
                    st.markdown(f"#### Q{i+1}. {q['question']}")
                    
                    # ë¼ë””ì˜¤ ë²„íŠ¼ (ì„ íƒì§€)
                    ans = st.radio(
                        "Select:", 
                        q['options'], 
                        key=f"q_{i}", 
                        index=None, 
                        label_visibility="collapsed"
                    )
                    
                    # ì •ë‹µ í™•ì¸ ë²„íŠ¼
                    if st.button(ui["quiz_check"], key=f"chk_{i}"):
                        if ans == q['answer']: 
                            st.success(ui["quiz_correct"])
                        else: 
                            st.error(ui["quiz_wrong"])
                        
                        # í•´ì„¤ ë³´ê¸°
                        with st.expander(ui["quiz_exp"]): 
                            st.write(q['explanation'])
                    st.divider()
            else:
                # ìƒì„± ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
                st.error(ui["err_json"])
                st.write(st.session_state.quiz_data)
    
    with t5: # ì˜¤ë””ì˜¤
        if st.button(ui["btn_gen"], key="audio"):
            # ì „ì œ ì¡°ê±´ í™•ì¸
            if st.session_state.summary:
                client = OpenAI(api_key=st.session_state.api_key)
                
                # [ê¸°ëŠ¥ 1] ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì œê±° í•¨ìˆ˜ (ë“£ê¸° í¸í•˜ê²Œ)
                def clean_markdown_for_speech(text):
                    # 1. í—¤ë” ì œê±° (### ë“±)
                    text = re.sub(r'#+\s?', '', text)
                    # 2. ë³¼ë“œì²´/ì´íƒ¤ë¦­ ì œê±° (** **)
                    text = re.sub(r'\*\*|__', '', text)
                    # 3. ë¶ˆí•„ìš”í•œ ê³µë°±/ì¤„ë°”ê¿ˆ ì •ë¦¬
                    text = re.sub(r'\n+', ' ', text)
                    return text.strip()

                # [ê¸°ëŠ¥ 2] ëª¨ë“  ìë£Œì˜ 'í•µì‹¬ ë‚´ìš©'ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (ì—…ê·¸ë ˆì´ë“œ)
                def extract_all_core_parts(text, ui_text):
                    start_marker = ui_text['h_bullet'] # "1. í•µì‹¬ ë‚´ìš© ìš”ì•½"
                    end_marker = ui_text['h_table']    # "2. ìƒì„¸ ìš”ì•½ í‘œ"
                    
                    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ startì™€ end ì‚¬ì´ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ (re.DOTALL: ì¤„ë°”ê¿ˆ í¬í•¨)
                    # íŒ¨í„´: (ì‹œì‘ë§ˆì»¤) ...ë‚´ìš©... (ëë§ˆì»¤)
                    pattern = f"{re.escape(start_marker)}(.*?){re.escape(end_marker)}"
                    matches = re.findall(pattern, text, re.DOTALL)
                    
                    if matches:
                        # ì¶”ì¶œëœ ëª¨ë“  ì„¹ì…˜ì„ í•˜ë‚˜ë¡œ í•©ì¹¨
                        combined_text = " ".join(matches)
                        return clean_markdown_for_speech(combined_text)
                    else:
                        # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ (ì˜ˆì™¸ ì²˜ë¦¬)
                        return clean_markdown_for_speech(text[:1000])

                try:
                    with st.spinner(ui["spin_audio"]):
                        # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì •ì œ
                        core_summary = extract_all_core_parts(st.session_state.summary, ui)
                        
                        # 2. ê¸¸ì´ ì œí•œ (OpenAI TTS í•œë„ 4096ì ê³ ë ¤, ì•ˆì „í•˜ê²Œ 4000ì)
                        if len(core_summary) > 4000:
                            final_input = core_summary[:4000] + "... (Content truncated due to length limit)"
                            st.caption("âš ï¸ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ì–´ ì•ë¶€ë¶„ 4000ìë§Œ ì¬ìƒë©ë‹ˆë‹¤.")
                        else:
                            final_input = core_summary

                        # 3. TTS ìƒì„±
                        audio = client.audio.speech.create(
                            model="tts-1",
                            voice="alloy",
                            input=final_input
                        )
                        
                        st.success("Audio generated! (Reading all 'Key Highlights')")
                        
                        # 4. ì¬ìƒ ë° ìŠ¤í¬ë¦½íŠ¸ í™•ì¸
                        st.audio(audio.content, format="audio/mp3")
                        
                        with st.expander("ğŸ“œ ì½ì–´ì¤€ ëŒ€ë³¸ (Script)"):
                            st.write(final_input)

                except Exception as e: 
                    st.error(f"Error: {str(e)}")
            else: 
                st.warning(ui["audio_warn"])
    
    with t6: # AI íŠœí„°
        chat_box = st.container(height=500)
        for m in st.session_state.messages: chat_box.chat_message(m["role"]).write(m["content"])
        
        if q := st.chat_input(ui["chat_ph"]):
            # ìœ ì € ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
            st.session_state.messages.append({"role":"user", "content":q})
            chat_box.chat_message("user").write(q)
            
            with st.spinner("Analyzing intent & Searching documents..."):
                try:
                    # === [í•µì‹¬ ë¡œì§] ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ë° ì¿¼ë¦¬ í™•ì¥ ===
                    q_lower = q.strip().lower()
                    
                    # 1. [ì „ì²´ ìš”ì•½ ëª¨ë“œ] ("ì „ë¶€", "all" ë“±)
                    if q_lower in ["all", "ì „ë¶€", "ì „ì²´", "everything", "ìš”ì•½í•´ì¤˜"]:
                        # ê²€ìƒ‰ íš¨ê³¼: ë¬¸ì„œ ì „ì²´ë¥¼ ì•„ìš°ë¥´ëŠ” í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
                        # ì§€ì‹œ íš¨ê³¼: ì „ì²´ë¥¼ ìƒì„¸íˆ ì •ë¦¬í•˜ë¼ëŠ” ëª…ë ¹ ì¶”ê°€
                        search_query = (
                            "Provide a comprehensive and very detailed summary of the ENTIRE provided material. "
                            "Cover all lectures, core concepts, structure, and main arguments from start to finish. "
                            "Do not miss any major sections."
                        )
                    
                    # 2. [ì‹œí—˜ ì „ëµ ëª¨ë“œ] ("ì‹œí—˜", "ìœ í˜•", "ì „ëµ", "ê³„íš" ë“±)
                    elif any(x in q_lower for x in ["ì‹œí—˜", "exam", "test", "ìœ í˜•", "type", "strategy", "plan", "ê³„íš", "ëŒ€ë¹„"]):
                        # ê²€ìƒ‰ íš¨ê³¼: [Practice Problem] íƒœê·¸ê°€ ë¶™ì€ ë‚´ìš© ìœ„ì£¼ë¡œ ê²€ìƒ‰ ìœ ë„
                        # ì§€ì‹œ íš¨ê³¼: ìŠ¤íƒ€ì¼ ë¶„ì„ ë° ì „ëµ ìˆ˜ë¦½ ìš”ì²­
                        search_query = (
                            f"User Question: '{q}'\n\n"
                            "Task: Act as an Exam Strategist. "
                            "1. Analyze the content labeled `[Practice Problem]` to identify exam styles (MCQ, Essay, etc.) and difficulty. "
                            "2. Summarize the types of questions that appear. "
                            "3. Provide a concrete study plan and preparation strategy based on these patterns."
                        )
                    
                    # 3. [íŠ¹ì • ìš©ì–´/ì¼ë°˜ ì§ˆë¬¸ ëª¨ë“œ]
                    else:
                        # ê²€ìƒ‰ íš¨ê³¼: í•´ë‹¹ ìš©ì–´ì™€ ê´€ë ¨ëœ ë¬¸ë§¥ ê²€ìƒ‰
                        # ì§€ì‹œ íš¨ê³¼: ë‹¨ë‹µí˜•ì´ ì•„ë‹Œ 'ìƒì„¸ ì„¤ëª…' ìœ ë„
                        search_query = (
                            f"Explain the concept of '{q}' in great detail. "
                            "Include its definition, context, related terms, and why it is important in this document."
                        )
                    
                    # RAG ì²´ì¸ ì‹¤í–‰ (search_query ì „ë‹¬)
                    # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ì˜ {question} ìë¦¬ì— ìœ„ì—ì„œ ë§Œë“  ê¸´ ì§€ì‹œì‚¬í•­ì´ ë“¤ì–´ê°‘ë‹ˆë‹¤.
                    response = st.session_state.chain.invoke({"query": search_query})
                    res = response['result']
                    
                except Exception as e:
                    res = f"Error: {str(e)}"
            
            # AI ì‘ë‹µ í‘œì‹œ ë° ì €ì¥
            chat_box.chat_message("assistant").write(res)
            st.session_state.messages.append({"role":"assistant", "content":res})

else:
    st.info(f"ğŸ‘ˆ {ui['sidebar_title']}")